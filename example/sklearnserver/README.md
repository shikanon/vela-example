# sklearn server ä½¿ç”¨

## å®‰è£… sklearn server

### æœ¬åœ°é•œåƒç¼–è¯‘è¿è¡Œ

```bash
# ç¼–è¯‘
docker build -t swr.cn-north-4.myhuaweicloud.com/hw-zt-k8s-images/sklearnserver -f sklearn.Dockerfile .
# è¿è¡Œ
docker run -it --rm -p 8080:8080 swr.cn-north-4.myhuaweicloud.com/hw-zt-k8s-images/sklearnserver
```

### k8sè¿è¡Œ

ä¸Šä¼ é•œåƒï¼š
```bash
docker build -t swr.cn-north-4.myhuaweicloud.com/hw-zt-k8s-images/sklearnserver:demo-iris -f sklearn.Dockerfile .
docker push swr.cn-north-4.myhuaweicloud.com/hw-zt-k8s-images/sklearnserver:demo-iris
```

ä½¿ç”¨ `vela up` éƒ¨ç½²:

```bash
$ vela up -f demo-iris-01.yaml
Parsing vela appfile ...
Load Template ...

Rendering configs for service (demo-iris)...
Writing deploy config to (.vela/deploy.yaml)

Applying application ...
Checking if app has been deployed...
App has not been deployed, creating a new deployment...
âœ… App has been deployed ğŸš€ğŸš€ğŸš€
    Port forward: vela port-forward demo-iris-01
             SSH: vela exec demo-iris-01
         Logging: vela logs demo-iris-01
      App status: vela status demo-iris-01
  Service status: vela status demo-iris-01 --svc demo-iris
```

éƒ¨ç½²å¥½åå¯ä»¥æµ‹è¯•ï¼š
```bash
$ curl -i -d '{"instances":[[5.1, 3.5, 1.4, 0.2]]}' -H "Content-Type: application/json" -X POST demo-iris.rcmd.testing.mpengine:8000/v1/models/model:predict
{"predictions": [0]}
```

## æ¥å£è¯´æ˜

### æœåŠ¡å­˜æ´»æ£€æµ‹

```bash
curl 127.0.0.1:8080/
# æˆ–è€…
curl 127.0.0.1:8080/v2/health/live
```

### æ¨¡å‹é¢„æµ‹

demo ç¤ºä¾‹æ¨¡å‹ä½¿ç”¨çš„æ˜¯ `iris` æ•°æ®è®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹æ³•è·å–ï¼š
```python
from sklearn import datasets

iris = datasets.load_iris()
X, y = iris.data, iris.target
print(X[0],y[0])
# [5.1 3.5 1.4 0.2] 0
```

é¢„æµ‹æäº¤æ•°æ®ä½¿ç”¨çš„ `POST` æ–¹æ³•ï¼Œæ•°æ®æ ¼å¼ä¸º`{"instances": <æ•°ç»„>}`ï¼š

```bash
$ curl -d '{"instances":[[5.1, 3.5, 1.4, 0.2]]}' -X POST 127.0.0.1:8080/v1/models/model:predict
{"predictions": [0]}

$ curl -d '{"instances":[[5.9, 3.0 , 5.1, 1.8]]}' -X POST 127.0.0.1:8080/v1/models/model:predict
{"predictions": [2]}
```


### å…¶ä»–æ¥å£å®ç°

kfserving æä¾›äº†å¤šç§æ–¹æ³•çš„æ¥å£ä¾›å®ç°ï¼Œè¯¦ç»†è§`kfserving/kfserving/kfserver.py`:
```python
...
def create_application(self):
    return tornado.web.Application([
        # Server Liveness API returns 200 if server is alive.
        (r"/", LivenessHandler),
        (r"/v2/health/live", LivenessHandler),
        (r"/v1/models",
            ListHandler, dict(models=self.registered_models)),
        (r"/v2/models",
            ListHandler, dict(models=self.registered_models)),
        # Model Health API returns 200 if model is ready to serve.
        (r"/v1/models/([a-zA-Z0-9_-]+)",
            HealthHandler, dict(models=self.registered_models)),
        (r"/v2/models/([a-zA-Z0-9_-]+)/status",
            HealthHandler, dict(models=self.registered_models)),
        (r"/v1/models/([a-zA-Z0-9_-]+):predict",
            PredictHandler, dict(models=self.registered_models)),
        (r"/v2/models/([a-zA-Z0-9_-]+)/infer",
            PredictHandler, dict(models=self.registered_models)),
        (r"/v1/models/([a-zA-Z0-9_-]+):explain",
            ExplainHandler, dict(models=self.registered_models)),
        (r"/v2/models/([a-zA-Z0-9_-]+)/explain",
            ExplainHandler, dict(models=self.registered_models)),
        (r"/v2/repository/models/([a-zA-Z0-9_-]+)/load",
            LoadHandler, dict(models=self.registered_models)),
        (r"/v2/repository/models/([a-zA-Z0-9_-]+)/unload",
            UnloadHandler, dict(models=self.registered_models)),
    ])
...
```